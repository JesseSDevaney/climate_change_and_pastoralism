{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "source_directory = \"../surveys/plain_txt/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract\n",
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_str_to_num(month_str):\n",
    "    month_dict = {\n",
    "                    'enero': \"1\",\n",
    "                    'febrero': \"2\",\n",
    "                    'marzo': \"3\",\n",
    "                    'abril': \"4\",\n",
    "                    'mayo': \"5\",\n",
    "                    'junio': \"6\",\n",
    "                    'julio': \"7\",\n",
    "                    'agosto': \"8\",\n",
    "                    'septiembre': \"9\", \n",
    "                    'octubre': \"10\",\n",
    "                    'noviembre': \"11\",\n",
    "                    'diciembre': \"12\"\n",
    "                  }\n",
    "\n",
    "    return month_dict[month_str]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_country(contents):\n",
    "    country_regex = r\"pa\\ws[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    country_search = re.findall(country_regex, contents)\n",
    "    if len(country_search) == 1:\n",
    "        country = country_search[0]\n",
    "    else:\n",
    "        country = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    country = country.strip()\n",
    "\n",
    "    return country\n",
    "\n",
    "\n",
    "def parse_interviewee(contents):\n",
    "    name_regex = r\"nombre de la persona[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    name_search = re.findall(name_regex, contents)\n",
    "    if len(name_search) == 1:\n",
    "        name = name_search[0]\n",
    "        if name == \"3\":\n",
    "            name = \"N/A\"\n",
    "    else:\n",
    "        alt_name_regex = r\"nombre de la persona[^\\n\\(]*\\(\\w* +([^\\n]*)\\n\"\n",
    "        alt_name_search = re.findall(alt_name_regex, contents)\n",
    "        if len(alt_name_search) == 1:\n",
    "            name = alt_name_search[0]\n",
    "            if name == \"3\":\n",
    "                name = \"N/A\"\n",
    "        else:\n",
    "            name = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    name = name.strip()\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def parse_sex(contents):\n",
    "    sex_regex = r\"g\\wnero de la persona[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    sex_search = re.findall(sex_regex, contents)\n",
    "    if len(sex_search) == 1:\n",
    "        sexes = re.split(r\"/\", sex_search[0])\n",
    "        sex = \"\"\n",
    "        if re.search(r\"x\", sexes[0]):\n",
    "            sex = \"male\"\n",
    "        elif re.search(r\"x\", sexes[1]):\n",
    "            sex = \"female\"\n",
    "    else:\n",
    "        sex = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    return sex\n",
    "\n",
    "\n",
    "def parse_ethnicity(contents):\n",
    "    ethnicity_regex = r\"etnia de la persona[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    ethnicity_search = re.findall(ethnicity_regex, contents)\n",
    "    if len(ethnicity_search) == 1:\n",
    "        ethnicity = ethnicity_search[0]\n",
    "    else:\n",
    "        ethnicity = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    ethnicity = ethnicity.strip()\n",
    "\n",
    "    if ethnicity == \"5\":\n",
    "        ethnicity = \"N/A\"\n",
    "\n",
    "    return ethnicity\n",
    "\n",
    "\n",
    "def parse_survey_date(contents):\n",
    "    date_regex = r\"fecha de la entre[^\\n: ]*:?[\\s]*([^\\n]*)\\n\"\n",
    "    date_search = re.findall(date_regex, contents)\n",
    "\n",
    "    if len(date_search) == 1:\n",
    "        date_str = date_search[0]\n",
    "        if re.search(r\"/\", date_str):\n",
    "            date_search = date_str.split(\"/\")\n",
    "            date_str = \"-\".join(date_search)\n",
    "        elif re.search(r\"-\", date_str):\n",
    "            date_str = date_str\n",
    "        elif date_str == \"6\":\n",
    "            date_str = \"N/A\"\n",
    "        else:\n",
    "            # try date in string format (i.e. 31 DE OCTUBRE)\n",
    "            date_string_regex = r\"fecha de la entre[^\\n: ]*:?[ ]*([^\\n]*)\\n\"\n",
    "            date_string_search = re.findall(date_string_regex, contents)\n",
    "\n",
    "            if len(date_string_search) == 1:\n",
    "                date_str = date_string_search[0]\n",
    "                date_str = date_str.strip()\n",
    "\n",
    "                parse_date_regex = r\"([\\d]+) *[\\w]+ *([\\w]+) *[\\w]* *([\\d]*)\"\n",
    "                parse_date_search = re.findall(parse_date_regex, date_str)\n",
    "                if len(parse_date_search) == 1:\n",
    "                    day = parse_date_search[0][0]\n",
    "                    month = parse_date_search[0][1]\n",
    "                    month = month_str_to_num(month)\n",
    "                    year = parse_date_search[0][2]\n",
    "                    date_str = day + \"-\" + month + \"-\" + year\n",
    "                else:\n",
    "                    date_str = \"UNENCOUNTERED FORMAT\"\n",
    "            else:\n",
    "                date_str = \"UNENCOUNTERED FORMAT\"\n",
    "    else:\n",
    "        date_str = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    if date_str != \"UNENCOUNTERED FORMAT\":\n",
    "        date_str = date_str.replace(\" \", \"\")\n",
    "        date_str = date_str.replace(\"Â¿\", \"\")\n",
    "\n",
    "    return date_str\n",
    "\n",
    "\n",
    "def parse_survey_hour(contents):\n",
    "    # survey hour\n",
    "    hour_list = re.findall(r\"hora de la entre[^\\n:]*:[\\s]*([^\\n]*)\\n\",\n",
    "                               contents)\n",
    "    hour_null_regex = r\"i-1\"\n",
    "    hour_period_regex = r\"([\\d]+[\\.]?[\\d]*)[\\w]*\"\n",
    "    hour_colon_regex = r\"([\\d]+[ ]?[:]?[ ]?[\\d]*)[\\w]*\"\n",
    "    hour_space_regex = r\"([\\d]+\\s[\\d]+)[\\w]*\"\n",
    "    hour_no_min_regex = r\"([\\d]+)[\\s]*[\\w]*\"\n",
    "\n",
    "    if len(hour_list) == 1:\n",
    "        hour_str = hour_list[0]\n",
    "        # handles time fields that contain no entry\n",
    "        if re.search(hour_null_regex, hour_str):\n",
    "            hour_str = \"N/A\"\n",
    "        elif re.search(r\"[\\d]{4}\", hour_str):\n",
    "            hour_regex = r\"([\\d]{4})\"\n",
    "            hour_search = re.findall(hour_regex, hour_str)\n",
    "            hour_str = hour_search[0][0:2] + \":\" + hour_search[0][2:4]\n",
    "        # times separated by period (i.e. 12.00, 8.00)\n",
    "        elif re.search(r\"\\.\", hour_str):\n",
    "            hour_list = re.findall(hour_period_regex, hour_str)\n",
    "            hour_str = hour_list[0]\n",
    "            hour_list = hour_str.split(\".\")\n",
    "            hour_str = \":\".join(hour_list)\n",
    "        # times separated by : (i.e. 12:00, 8:30)\n",
    "        elif re.search(r\":\", hour_str):\n",
    "            hour_list = re.findall(hour_colon_regex, hour_str)\n",
    "            hour_str = hour_list[0]\n",
    "        # times separated by spaces (i.e. 12 00 hr)\n",
    "        elif re.search(hour_space_regex, hour_str):\n",
    "            hour_list = re.findall(hour_space_regex, hour_str)\n",
    "            hour_str = hour_list[0]\n",
    "            hour_list = hour_str.split(\" \")\n",
    "            hour_str = \":\".join(hour_list)\n",
    "        # times with no minutes field (i.e. 12hr, 8hrs, 8 h)\n",
    "        elif re.search(hour_no_min_regex, hour_str):\n",
    "            hour_list = re.findall(hour_no_min_regex, hour_str)\n",
    "            hour_str = hour_list[0] + \":\" + \"00\"\n",
    "    else:\n",
    "        hour_str = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    if hour_str != \"UNENCOUNTERED FORMAT\":\n",
    "        hour_str = hour_str.replace(\" \", \"\")\n",
    "\n",
    "    return hour_str\n",
    "\n",
    "\n",
    "def parse_latitude(contents):\n",
    "    coordinates_regex = r\"coordenadas geo[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    coordinate_search = re.findall(coordinates_regex, contents)\n",
    "    \n",
    "    if len(coordinate_search) == 1:\n",
    "        coordinate_list = re.split(\"/\", coordinate_search[0])\n",
    "        # decimal coordinates\n",
    "        dec_regex = r\"-\\d+.\\d+\"\n",
    "        arc_regex = r\"(\\d+,?\\d*)\\W\"\n",
    "        empty_regex = r\"\\|_+\\|\"\n",
    "        \n",
    "        if len(coordinate_list) == 2:\n",
    "            if re.search(dec_regex, coordinate_list[1]):\n",
    "                latitude_search = re.findall(dec_regex, coordinate_list[1])\n",
    "                if len(latitude_search) == 1:\n",
    "                    latitude = latitude_search[0]\n",
    "                    latitude = latitude.replace(\",\", \".\")\n",
    "                else:\n",
    "                    latitude = \"UNENCOUNTERED FORMAT\"\n",
    "            elif re.search(arc_regex, coordinate_list[1]):\n",
    "                # latitude (deg, arcmin, arcsec)\n",
    "                latitude_list = re.findall(arc_regex, coordinate_list[1])\n",
    "                if len(latitude_list) == 3:\n",
    "                    lat_deg = float(latitude_list[0])\n",
    "                    lat_arcmin = float(latitude_list[1])\n",
    "                    lat_arcsec_str = latitude_list[2].replace(\",\", \".\")\n",
    "                    lat_arcsec = float(lat_arcsec_str)\n",
    "\n",
    "                    latitude = str(-1 * (lat_deg \n",
    "                                         + (lat_arcmin / 60)\n",
    "                                         + (lat_arcsec / 3600)))\n",
    "                else:\n",
    "                    latitude = \"UNENCOUNTERED FORMAT\"\n",
    "            elif re.search(empty_regex, coordinate_list[0]):\n",
    "                latitude = \"\"\n",
    "            else:\n",
    "                latitude = \"UNENCOUNTERED FORMAT\"\n",
    "        else:\n",
    "            coordinates = re.findall(dec_regex, coordinate_search[0])\n",
    "            if len(coordinates) == 2:\n",
    "                latitude = coordinates[1]\n",
    "            else:\n",
    "                latitude = \"UNENCOUNTERED FORMAT\"\n",
    "    else:\n",
    "        latitude = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    return latitude\n",
    "\n",
    "\n",
    "def parse_longitude(contents):\n",
    "    coordinates_regex = r\"coordenadas geo[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    coordinate_search = re.findall(coordinates_regex, contents)\n",
    "    \n",
    "    if len(coordinate_search) == 1:\n",
    "        coordinate_list = re.split(\"/\", coordinate_search[0])\n",
    "        # decimal coordinates\n",
    "        dec_regex = r\"-\\d+.\\d+\"\n",
    "        arc_regex = r\"(\\d+,?\\d*)\\W\"\n",
    "        empty_regex = r\"\\|_+\\|\"\n",
    "                           \n",
    "        if len(coordinate_list) == 2:\n",
    "            if re.search(dec_regex, coordinate_list[0]):\n",
    "                longitude_search = re.findall(dec_regex, coordinate_list[0])\n",
    "                if len(longitude_search) != 0:\n",
    "                    longitude = longitude_search[0]\n",
    "                    longitude = longitude.replace(\",\", \".\")\n",
    "                else:\n",
    "                    longitude = \"UNENCOUNTERED FORMAT\"\n",
    "            elif re.search(arc_regex, coordinate_list[0]):\n",
    "                # longitude (deg, arcmin, arcsec)\n",
    "                longitude_list = re.findall(arc_regex, coordinate_list[0])\n",
    "                if len(longitude_list) == 3:\n",
    "                    lon_deg = float(longitude_list[0])\n",
    "                    lon_arcmin = float(longitude_list[1])\n",
    "                    lon_arcsec_str = longitude_list[2].replace(\",\", \".\")\n",
    "                    lon_arcsec = float(lon_arcsec_str)\n",
    "\n",
    "                    longitude = str(-1 * (lon_deg \n",
    "                                          + (lon_arcmin / 60)\n",
    "                                          + (lon_arcsec / 3600)))\n",
    "                else:\n",
    "                    longitude = \"UNENCOUNTERED FORMAT\"\n",
    "            elif re.search(empty_regex, coordinate_list[1]):\n",
    "                longitude = \"\"\n",
    "            else:\n",
    "                longitude = \"UNENCOUNTERED FORMAT\"\n",
    "        else:\n",
    "            coordinates = re.findall(dec_regex, coordinate_search[0])\n",
    "            if len(coordinates) == 2:\n",
    "                longitude = coordinates[0]\n",
    "            else:\n",
    "                longitude = \"UNENCOUNTERED FORMAT\"\n",
    "    else:\n",
    "        longitude = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    longitude = longitude.strip()\n",
    "\n",
    "    if re.search(r\"-[\\d]*-[\\d]+\", longitude):\n",
    "        longitude = \"-\" + \".\".join(longitude[1:].split(\"-\"))\n",
    "\n",
    "    return longitude\n",
    "\n",
    "\n",
    "def parse_region(contents):\n",
    "    region_regex = r\"regi\\wn[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    region_search = re.findall(region_regex, contents)\n",
    "    if len(region_search) == 1:\n",
    "        region = region_search[0]\n",
    "    else:\n",
    "        region = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    if region == \"3\":\n",
    "        region = \"N/A\"\n",
    "\n",
    "    return region\n",
    "\n",
    "\n",
    "def parse_province(contents):\n",
    "    province_regex = r\"provincia[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    province_search = re.findall(province_regex, contents)\n",
    "    if len(province_search) == 1:\n",
    "        province = province_search[0]\n",
    "    else:\n",
    "        province = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    province = province.strip() \n",
    "\n",
    "    return province\n",
    "\n",
    "\n",
    "def parse_department(contents):\n",
    "    department_regex = r\"departa[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    department_search = re.findall(department_regex, contents)\n",
    "    if len(department_search) == 1:\n",
    "        department = department_search[0]\n",
    "    else:\n",
    "        department = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    department = department.strip() \n",
    "\n",
    "    return department\n",
    "\n",
    "\n",
    "def parse_loc_type(contents):\n",
    "    loc_type_regex = r\"tipo de localidad[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "    loc_type_search = re.findall(loc_type_regex, contents)\n",
    "    if len(loc_type_search) == 1:\n",
    "        loc_types = re.split(r\"/\", loc_type_search[0])\n",
    "\n",
    "        if len(loc_types) == 5: \n",
    "            if re.search(r\"x\", loc_types[0]):\n",
    "                loc_type = \"comunidad\"\n",
    "            elif re.search(r\"x\", loc_types[1]):\n",
    "                loc_type = \"barrio\"\n",
    "            elif re.search(r\"x\", loc_types[2]):\n",
    "                loc_type = \"campamiento\"\n",
    "            elif re.search(r\"x\", loc_types[3]):\n",
    "                loc_type = \"paraje\"\n",
    "            elif re.search(r\"x\", loc_types[4]):\n",
    "                loc_type = \"otro\"\n",
    "            else:\n",
    "                loc_type = \"N/A\"\n",
    "        elif ((len(loc_types) == 1) \n",
    "              and not re.search(r\"(\\w+)[ ]+([^\\n]+)\", loc_type_search[0])): \n",
    "            loc_type = loc_type_search[0]\n",
    "        else:\n",
    "            loc_str_regex = r\"(\\w+)[ ]+([^\\n]+)\"\n",
    "            loc_str_search = re.findall(loc_str_regex, loc_type_search[0])\n",
    "            if len(loc_str_search) == 1: \n",
    "                loc_type = loc_str_search[0][0]\n",
    "            else:\n",
    "                loc_type = loc_str_search\n",
    "    else:\n",
    "        loc_type = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    loc_type = loc_type.strip()\n",
    "\n",
    "    return loc_type\n",
    "\n",
    "\n",
    "def parse_loc_specific(contents):\n",
    "    # location_type_specific\n",
    "    loc_specific_regex = r\"\\]\\s*especificar:?[ _]*([\\w\\d \\t,\\.]*)\"\n",
    "    loc_specific_search = re.findall(loc_specific_regex, contents)\n",
    "    if len(loc_specific_search) == 1:\n",
    "        loc_specific = loc_specific_search[0]\n",
    "    else:\n",
    "        loc_type_regex = r\"tipo de localidad[^\\n:]*:[\\s]*([^\\n]*)\\n\"\n",
    "        loc_type_search = re.findall(loc_type_regex, contents)\n",
    "        if len(loc_type_search) == 1:\n",
    "            loc_str_regex = r\"(\\w+)[ ]+([^\\n/]+)\"\n",
    "            loc_str_search = re.findall(loc_str_regex, loc_type_search[0])\n",
    "            if len(loc_str_search) == 1: \n",
    "                loc_specific = loc_str_search[0][1]\n",
    "            else:\n",
    "                loc_str_regex = r\"\\][ _]*([\\w\\d \\t,]*[_]*[\\w\\d \\t,]*)\"\n",
    "                loc_str_search = re.findall(loc_str_regex, loc_type_search[0])\n",
    "                if len(loc_str_search) == 1: \n",
    "                    loc_specific = loc_str_search[0]\n",
    "                else:\n",
    "                    loc_specific = \"N/A\"\n",
    "        else:\n",
    "            loc_specific = \"UNENCOUNTERED FORMAT\"\n",
    "\n",
    "    if loc_specific == \"\":\n",
    "        loc_specific = \"N/A\"\n",
    "\n",
    "    loc_specific = loc_specific.replace(\"_\", \" \")\n",
    "    loc_specific = loc_specific.strip()\n",
    "\n",
    "    return loc_specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the Whole File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(source_directory):\n",
    "    dataset = []\n",
    "\n",
    "    for process_file in os.listdir(source_directory):\n",
    "        file_path = os.path.join(source_directory, process_file)\n",
    "\n",
    "        # with statements automatically control the closing of files\n",
    "        with open(file_path, \"r\") as file:\n",
    "            contents = file.read()\n",
    "            contents = contents.lower()\n",
    "\n",
    "            parsers = {\n",
    "                          \"country\": parse_country,\n",
    "                          \"interviewee\": parse_interviewee,\n",
    "                          \"sex\": parse_sex,\n",
    "                          \"ethnicity\": parse_ethnicity,\n",
    "                          \"survey_date\": parse_survey_date,\n",
    "                          \"survey_hour\": parse_survey_hour,\n",
    "                          \"latitude\": parse_latitude,\n",
    "                          \"longitude\": parse_longitude,\n",
    "                          \"region\": parse_region, \n",
    "                          \"province\": parse_province, \n",
    "                          \"department\": parse_department, \n",
    "                          \"loc_type\": parse_loc_type,\n",
    "                          \"loc_specific\": parse_loc_specific\n",
    "                      }\n",
    "\n",
    "            data_dict = {}\n",
    "            data_dict[\"filename\"] = process_file\n",
    "\n",
    "            for key, parser in parsers.items():\n",
    "                data_dict[key] = parser(contents)\n",
    "\n",
    "            dataset.append(data_dict)\n",
    "\n",
    "    # convert list to DataFrame\n",
    "    raw_df = pd.DataFrame(data=dataset)\n",
    "\n",
    "    return raw_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform\n",
    "### Pipeline Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_pipeline(dataf):\n",
    "    return dataf.copy() \n",
    "\n",
    "\n",
    "def handle_null_data(dataf):\n",
    "    # fill missing values with null\n",
    "    dataf = dataf.replace(\"\", np.NaN)\n",
    "    \n",
    "    return dataf\n",
    "\n",
    "\n",
    "def clean_columns(dataf):\n",
    "    lat_coords = dataf[\"latitude\"].astype(float)\n",
    "    long_coords = dataf[\"longitude\"].astype(float)\n",
    "    dataf[\"latitude\"] = lat_coords.where(long_coords < -50, long_coords)\n",
    "    dataf[\"longitude\"] = long_coords.where(long_coords < -50, lat_coords)\n",
    "    \n",
    "    return dataf\n",
    "\n",
    "\n",
    "def set_dtypes(dataf):\n",
    "    dataf[\"latitude\"] = dataf[\"latitude\"].astype(float)\n",
    "    dataf[\"longitude\"] = dataf[\"longitude\"].astype(float)\n",
    "    \n",
    "    return dataf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Raw and Cleaned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = process_files(source_directory)\n",
    "\n",
    "clean_df = (raw_df\n",
    "            .pipe(start_pipeline)\n",
    "            .pipe(handle_null_data)\n",
    "            .pipe(clean_columns)\n",
    "            .pipe(set_dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load\n",
    "### Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_directory = \"../datasets/\"\n",
    "filename = \"section_1.csv\"\n",
    "file_path = os.path.join(datasets_directory, filename)\n",
    "\n",
    "clean_df.to_csv(file_path, index=False, na_rep=\"null\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Testing Code\n",
    "### View the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Each Column for Parsing Errors and Standardize Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_check = clean_df.columns\n",
    "cols_to_drop = [\"filename\", \"interviewee\"]\n",
    "\n",
    "cols_to_check = cols_to_check.drop(cols_to_drop)\n",
    "\n",
    "for col in cols_to_check:\n",
    "    print(\"*\" * 50)\n",
    "    print(\" \" * 5 + col)\n",
    "    print(clean_df[col].value_counts(dropna=False))\n",
    "    print(\"*\" * 50)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[clean_df.duplicated(subset=[\"interviewee\", \"sex\"], keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitude_range = (clean_df.longitude.min(),   clean_df.longitude.max())      \n",
    "latitude_range = (clean_df.latitude.min(), clean_df.latitude.max())\n",
    "\n",
    "print(\"Longitude Range: {}\".format(longitude_range))\n",
    "print(\"Latitude Range: {}\".format(latitude_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.stock_img()\n",
    "ax.gridlines()\n",
    "ax.coastlines()\n",
    "ax.set_extent([-170, -20, -80, 10], crs=ccrs.PlateCarree())\n",
    "\n",
    "plt.scatter(x=clean_df[\"longitude\"], y=clean_df[\"latitude\"], \n",
    "            transform=ccrs.PlateCarree(), color=\"red\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
